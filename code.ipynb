import cv2
import matplotlib.pyplot as plt

# Configuration files for the model
config_file = "ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt"
frozen_model = "frozen_inference_graph.pb"
model1 = cv2.dnn_DetectionModel(frozen_model, config_file)

# Load class labels from the file
classLabels = []
file_name = 'Labels.txt'
with open(file_name, 'rt') as fpt:
    classLabels = fpt.read().rstrip('\n').split('\n')
print(classLabels)

# Test accessing a specific class label
print(classLabels[74])  # Ensure this index exists in Labels.txt

# Set input properties for the model
model1.setInputSize(320, 320)
model1.setInputScale(1.0 / 127.5)
model1.setInputMean((127.5, 127.5, 127.5))
model1.setInputSwapRB(True)

# Load and display the image
img = cv2.imread('image8.jpg')
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

# Perform object detection on the image
ClassIndex, confidence, bbox = model1.detect(img, confThreshold=0.5)
print(ClassIndex)

# Draw bounding boxes and labels on the image
font_scale = 1
font = cv2.FONT_HERSHEY_PLAIN
for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):
    cv2.rectangle(img, boxes, (0, 0, 255), 2)
    cv2.putText(img, classLabels[ClassInd - 1], (boxes[0] + 10, boxes[1] + 30), font, fontScale=font_scale, color=(255, 0, 0), thickness=1)

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.show()

# Video processing part
cap = cv2.VideoCapture("video.mp4")

# Check if the video is opened correctly
if not cap.isOpened():
    cap = cv2.VideoCapture(0)
if not cap.isOpened():
    raise IOError("Cannot open video")

font_scale = 3
font = cv2.FONT_HERSHEY_PLAIN

# Process video frames
while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # Perform detection on the frame
    ClassIndex, confidence, bbox = model1.detect(frame, confThreshold=0.55)
    
    if len(ClassIndex) != 0:
        for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):
            if ClassInd <= len(classLabels):
                cv2.rectangle(frame, boxes, (0, 0, 255), 2)
                cv2.putText(frame, classLabels[ClassInd - 1], (boxes[0] + 10, boxes[1] + 30), font, fontScale=font_scale, color=(255, 0, 0), thickness=2)

    # Display the frame
    cv2.imshow('video', frame)
    
    # Break on 'q' key press
    if cv2.waitKey(2) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

